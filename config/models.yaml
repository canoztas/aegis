# Aegis V2 Model Configuration
# This file defines providers and models for the enhanced registry.
#
# Environment variable syntax: ${VAR_NAME}
# Example: api_key: ${OPENAI_API_KEY}

# Provider Definitions
providers:
  # Ollama - Local LLM provider
  - name: ollama
    type: llm
    base_url: ${OLLAMA_BASE_URL:-http://localhost:11434}
    rate_limit_per_second: 10.0
    timeout_seconds: 600
    retry_max_attempts: 3
    retry_backoff_factor: 2.0
    enabled: true

  # OpenAI - Cloud LLM provider
  - name: openai
    type: llm
    base_url: https://api.openai.com/v1
    rate_limit_per_second: 5.0
    timeout_seconds: 60
    retry_max_attempts: 3
    retry_backoff_factor: 2.0
    enabled: true

  # Anthropic - Claude API
  - name: anthropic
    type: llm
    base_url: https://api.anthropic.com/v1
    rate_limit_per_second: 5.0
    timeout_seconds: 60
    retry_max_attempts: 3
    retry_backoff_factor: 2.0
    enabled: true

# Model Definitions
models:
  # HuggingFace Local - Fast Triage Classifier
  - provider: huggingface
    model_id: "hf:codebert-insecure"
    display_name: "CodeBERT Insecure Code Detector"
    model_name: "mrm8488/codebert-base-finetuned-detect-insecure-code"
    role: triage
    config:
      weight: 0.8
      supports_streaming: false
      supports_json: false
      task_type: "text-classification"
      parser_id: "classification"
      runtime:
        device_preference: ["cuda", "cpu"]
        dtype: "fp32"
        max_concurrency: 4

  # Ollama Models - Scan Role
  - provider: ollama
    model_id: "ollama:qwen2.5-coder:7b"
    display_name: "Qwen 2.5 Coder 7B"
    model_name: "qwen2.5-coder:7b"
    role: scan
    config:
      weight: 1.0
      supports_streaming: true
      supports_json: true

  - provider: ollama
    model_id: "ollama:codellama:7b"
    display_name: "CodeLlama 7B"
    model_name: "codellama:7b"
    role: scan
    config:
      weight: 1.0
      supports_streaming: true
      supports_json: true

  # Ollama Models - Triage Role (faster models for initial screening)
  - provider: ollama
    model_id: "ollama:qwen2.5-coder:7b:triage"
    display_name: "Qwen 2.5 Coder 7B (Triage)"
    model_name: "qwen2.5-coder:7b"
    role: triage
    config:
      weight: 1.0
      supports_streaming: true
      supports_json: true

  # Ollama Models - Deep Scan Role (thorough analysis)
  - provider: ollama
    model_id: "ollama:qwen2.5-coder:14b:deep"
    display_name: "Qwen 2.5 Coder 14B (Deep Scan)"
    model_name: "qwen2.5-coder:14b"
    role: deep_scan
    config:
      weight: 2.0
      supports_streaming: true
      supports_json: true

  # Ollama Models - Judge Role (conflict resolution)
  - provider: ollama
    model_id: "ollama:qwen2.5-coder:32b:judge"
    display_name: "Qwen 2.5 Coder 32B (Judge)"
    model_name: "qwen2.5-coder:32b"
    role: judge
    config:
      weight: 3.0
      supports_streaming: true
      supports_json: true

  # OpenAI Models (require OPENAI_API_KEY environment variable)
  - provider: openai
    model_id: "openai:gpt-4o"
    display_name: "GPT-4o"
    model_name: "gpt-4o"
    role: deep_scan
    config:
      api_key: ${OPENAI_API_KEY}
      weight: 3.0
      supports_streaming: true
      supports_json: true
      max_tokens: 4096

  - provider: openai
    model_id: "openai:gpt-4o-mini"
    display_name: "GPT-4o Mini"
    model_name: "gpt-4o-mini"
    role: triage
    config:
      api_key: ${OPENAI_API_KEY}
      weight: 1.5
      supports_streaming: true
      supports_json: true
      max_tokens: 2048

  # Anthropic Models (require ANTHROPIC_API_KEY environment variable)
  - provider: anthropic
    model_id: "anthropic:claude-3-opus-20240229"
    display_name: "Claude 3 Opus"
    model_name: "claude-3-opus-20240229"
    role: judge
    config:
      api_key: ${ANTHROPIC_API_KEY}
      weight: 4.0
      supports_streaming: true
      supports_json: true
      max_tokens: 4096

  - provider: anthropic
    model_id: "anthropic:claude-3-sonnet-20240229"
    display_name: "Claude 3 Sonnet"
    model_name: "claude-3-sonnet-20240229"
    role: deep_scan
    config:
      api_key: ${ANTHROPIC_API_KEY}
      weight: 2.5
      supports_streaming: true
      supports_json: true
      max_tokens: 4096

  - provider: anthropic
    model_id: "anthropic:claude-3-haiku-20240307"
    display_name: "Claude 3 Haiku"
    model_name: "claude-3-haiku-20240307"
    role: triage
    config:
      api_key: ${ANTHROPIC_API_KEY}
      weight: 1.5
      supports_streaming: true
      supports_json: true
      max_tokens: 2048

# Role Descriptions:
# - scan: General purpose security scanning (default)
# - triage: Fast initial screening to identify potential issues
# - deep_scan: Thorough analysis of flagged code sections
# - judge: Resolve conflicts between models during consensus
# - explain: Generate detailed explanations of findings
